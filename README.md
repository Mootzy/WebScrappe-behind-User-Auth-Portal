# WebScrapper-behind-User-Auth.-Portal

Python 3.9 WebScrapper that takes in information gathered user "SECURED" portal and submits headers to reference as though it were a user.

Takes in CURL command from dev tools network pass, uses gathered information and a user's credentials to log into secure service

Scrape d2l, educational college based platform, for professors latest announcments. 

Incorporates Beautiful soup, lxml(HTML parser), and requests packages 

Initially all html source files we're also hashed and would throw error if trying to access open URL.

So techniqually it does the whole charade twice, then parses, formats, and decomposes the needles information.... of which there was thousands and thousands of lines. 

People sure do love their JavaScript/html<Divs> 
  

 
HUGE THANKS TO : https://curl.trillworks.com/#python for processing google chrome Dev Tools returnd cUrl commands
